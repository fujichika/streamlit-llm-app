import os
from dotenv import load_dotenv
import streamlit as st
from langchain.chat_models import ChatOpenAI
from langchain.schema import SystemMessage, HumanMessage

# ç’°å¢ƒå¤‰æ•°èª­ã¿è¾¼ã¿
load_dotenv()
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")

# Streamlit ã‚¢ãƒ—ãƒªè¨­å®š
st.set_page_config(page_title="LLM Webã‚¢ãƒ—ãƒª", page_icon="ğŸ¤–")

# ã‚¢ãƒ—ãƒªæ¦‚è¦è¡¨ç¤º
st.title("ğŸ’¬ LLM Webã‚¢ãƒ—ãƒª")
st.write("""
ã“ã®ã‚¢ãƒ—ãƒªã¯ã€ã‚ãªãŸã®è³ªå•ã«LLMãŒå›ç­”ã—ã¾ã™ã€‚
ä¸‹è¨˜ã®æ‰‹é †ã§ä½¿ã£ã¦ãã ã•ã„ï¼š
1. å°‚é–€å®¶ã®ç¨®é¡ã‚’ãƒ©ã‚¸ã‚ªãƒœã‚¿ãƒ³ã‹ã‚‰é¸æŠ
2. ãƒ†ã‚­ã‚¹ãƒˆã‚’å…¥åŠ›
3. ã€Œé€ä¿¡ã€ã‚’æŠ¼ã™ã¨ã€é¸æŠã—ãŸå°‚é–€å®¶ã«ãªã‚Šãã£ãŸLLMãŒå›ç­”ã—ã¾ã™
""")

# å°‚é–€å®¶ã®ç¨®é¡ã‚’é¸æŠ
expert_type = st.radio(
    "å°‚é–€å®¶ã®ç¨®é¡ã‚’é¸ã‚“ã§ãã ã•ã„",
    ("æ—…è¡Œãƒ—ãƒ©ãƒ³ãƒŠãƒ¼", "æ­´å²ç ”ç©¶è€…")
)

# ãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›
user_input = st.text_area("è³ªå•ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")

# LLMå‘¼ã³å‡ºã—é–¢æ•°
def get_llm_response(expert, text):
    if expert == "æ—…è¡Œãƒ—ãƒ©ãƒ³ãƒŠãƒ¼":
        system_prompt = "ã‚ãªãŸã¯æ—…è¡Œãƒ—ãƒ©ãƒ³ã®å°‚é–€å®¶ã§ã™ã€‚æ—…è¡Œè€…ã®å¸Œæœ›ã«åˆã‚ã›ãŸæœ€é©ãªæ—…è¡Œãƒ—ãƒ©ãƒ³ã‚’ææ¡ˆã—ã¦ãã ã•ã„ã€‚"
    elif expert == "æ­´å²ç ”ç©¶è€…":
        system_prompt = "ã‚ãªãŸã¯æ­´å²ã®å°‚é–€å®¶ã§ã™ã€‚è³ªå•ã«å¯¾ã—ã¦æ­´å²çš„äº‹å®Ÿã¨èƒŒæ™¯ã‚’è©³ã—ãèª¬æ˜ã—ã¦ãã ã•ã„ã€‚"
    else:
        system_prompt = "ã‚ãªãŸã¯æœ‰èƒ½ãªã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚"

    llm = ChatOpenAI(
        model_name="gpt-4o-mini",
        temperature=0.7,
        openai_api_key=OPENAI_API_KEY
    )

    messages = [
        SystemMessage(content=system_prompt),
        HumanMessage(content=text)
    ]

    response = llm(messages)
    return response.content

# å®Ÿè¡Œãƒœã‚¿ãƒ³
if st.button("é€ä¿¡"):
    if user_input.strip():
        answer = get_llm_response(expert_type, user_input)
        st.subheader("å›ç­”")
        st.write(answer)
    else:
        st.warning("è³ªå•ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")


